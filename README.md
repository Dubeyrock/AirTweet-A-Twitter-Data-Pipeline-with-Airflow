# AirTweet-A-Twitter-Data-Pipeline-with-Airflow

AirTweet is an end-to-end data engineering project that demonstrates how to build a Twitter data pipeline using Apache Airflow, Python, and AWS. The pipeline extracts tweets using the Twitter API, transforms the data, and loads the final results into Amazon S3. 


## Project Overview

AirTweet is an end-to-end data engineering project that demonstrates how to build a Twitter data pipeline using Apache Airflow, Python, and AWS. The pipeline extracts tweets using the Twitter API, transforms the data, and loads the final results into Amazon S3. This project is ideal for beginners who want to learn about data engineering workflows, ETL (Extract, Transform, Load) processes, and cloud deployment.

## Key Features

Data Extraction: Fetch tweets using the Twitter API.

Data Transformation: Process and clean tweets using Python.

Pipeline Orchestration: Deploy the workflow on Apache Airflow.

Cloud Storage: Store the processed data in Amazon S3.

Scalability: Deploy Airflow on an EC2 instance for better scalability



## Tech Stack

Programming Language: Python

Orchestration Tool: Apache Airflow

Cloud Storage: Amazon S3

Deployment: AWS EC2

API: Twitter API (v2)



## screenshot 

![image](https://github.com/user-attachments/assets/da001ca6-2a18-4d71-a0ae-0355fe8ee726)
